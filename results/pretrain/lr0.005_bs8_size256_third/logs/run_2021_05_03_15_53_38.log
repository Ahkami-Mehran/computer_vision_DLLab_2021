2021-05-03 15:53:53,182 INFO bs = 8  
snapshot_freq = 1  
data_folder = crops/images/  
model_folder = results/pretrain/lr0.005_bs8_size256_third/models  
lr = 0.005  
output_folder = results/pretrain/lr0.005_bs8_size256_third  
exp_name = lr0.005_bs8_size256_third  
size = 256  
exp_suffix = third  
output_root = results  
weights_init = pretrain_weights_init.pth  
logs_folder = results/pretrain/lr0.005_bs8_size256_third/logs
2021-05-03 15:53:53,185 INFO train_data 60000
2021-05-03 15:53:53,185 INFO val_data 1000
2021-05-03 15:53:53,185 INFO Epoch 0
2021-05-03 15:54:08,434 INFO Training: [epoch:1, batch:    50/7500] loss: 1.404
2021-05-03 15:54:22,865 INFO Training: [epoch:1, batch:   100/7500] loss: 1.128
2021-05-03 15:54:34,902 INFO Training: [epoch:1, batch:   150/7500] loss: 0.924
2021-05-03 15:54:48,314 INFO Training: [epoch:1, batch:   200/7500] loss: 0.824
2021-05-03 15:55:51,834 INFO Training: [epoch:1, batch:   250/7500] loss: 0.737
2021-05-03 15:56:08,017 INFO Training: [epoch:1, batch:   300/7500] loss: 0.685
2021-05-03 15:56:21,718 INFO Training: [epoch:1, batch:   350/7500] loss: 0.638
2021-05-03 15:56:32,333 INFO Training: [epoch:1, batch:   400/7500] loss: 0.603
2021-05-03 15:56:43,335 INFO Training: [epoch:1, batch:   450/7500] loss: 0.582
2021-05-03 15:56:57,191 INFO Training: [epoch:1, batch:   500/7500] loss: 0.555
2021-05-03 15:57:11,903 INFO Training: [epoch:1, batch:   550/7500] loss: 0.535
2021-05-03 15:57:25,582 INFO Training: [epoch:1, batch:   600/7500] loss: 0.522
2021-05-03 15:57:36,667 INFO Training: [epoch:1, batch:   650/7500] loss: 0.506
2021-05-03 15:57:46,049 INFO Training: [epoch:1, batch:   700/7500] loss: 0.494
2021-05-03 15:58:05,313 INFO Training: [epoch:1, batch:   750/7500] loss: 0.489
2021-05-03 15:58:17,941 INFO Training: [epoch:1, batch:   800/7500] loss: 0.476
2021-05-03 15:58:27,750 INFO Training: [epoch:1, batch:   850/7500] loss: 0.469
2021-05-03 15:58:39,392 INFO Training: [epoch:1, batch:   900/7500] loss: 0.458
2021-05-03 15:58:51,077 INFO Training: [epoch:1, batch:   950/7500] loss: 0.449
2021-05-03 15:59:02,887 INFO Training: [epoch:1, batch:  1000/7500] loss: 0.443
2021-05-03 15:59:18,702 INFO Training: [epoch:1, batch:  1050/7500] loss: 0.433
2021-05-03 15:59:30,255 INFO Training: [epoch:1, batch:  1100/7500] loss: 0.426
2021-05-03 15:59:40,218 INFO Training: [epoch:1, batch:  1150/7500] loss: 0.423
2021-05-03 15:59:50,070 INFO Training: [epoch:1, batch:  1200/7500] loss: 0.419
2021-05-03 16:00:03,715 INFO Training: [epoch:1, batch:  1250/7500] loss: 0.415
2021-05-03 16:00:16,614 INFO Training: [epoch:1, batch:  1300/7500] loss: 0.413
2021-05-03 16:00:28,554 INFO Training: [epoch:1, batch:  1350/7500] loss: 0.410
2021-05-03 16:00:38,154 INFO Training: [epoch:1, batch:  1400/7500] loss: 0.407
2021-05-03 16:00:47,340 INFO Training: [epoch:1, batch:  1450/7500] loss: 0.404
2021-05-03 16:00:58,812 INFO Training: [epoch:1, batch:  1500/7500] loss: 0.400
2021-05-03 16:01:24,972 INFO Training: [epoch:1, batch:  1550/7500] loss: 0.396
2021-05-03 16:02:12,106 INFO Training: [epoch:1, batch:  1600/7500] loss: 0.392
2021-05-03 16:02:28,330 INFO Training: [epoch:1, batch:  1650/7500] loss: 0.388
2021-05-03 16:02:43,458 INFO Training: [epoch:1, batch:  1700/7500] loss: 0.386
2021-05-03 16:02:54,292 INFO Training: [epoch:1, batch:  1750/7500] loss: 0.383
2021-05-03 16:03:05,965 INFO Training: [epoch:1, batch:  1800/7500] loss: 0.381
2021-05-03 16:03:16,935 INFO Training: [epoch:1, batch:  1850/7500] loss: 0.377
2021-05-03 16:03:28,611 INFO Training: [epoch:1, batch:  1900/7500] loss: 0.375
2021-05-03 16:03:41,149 INFO Training: [epoch:1, batch:  1950/7500] loss: 0.372
2021-05-03 16:03:51,082 INFO Training: [epoch:1, batch:  2000/7500] loss: 0.369
2021-05-03 16:04:04,896 INFO Training: [epoch:1, batch:  2050/7500] loss: 0.367
2021-05-03 16:04:16,488 INFO Training: [epoch:1, batch:  2100/7500] loss: 0.365
2021-05-03 16:04:27,054 INFO Training: [epoch:1, batch:  2150/7500] loss: 0.361
2021-05-03 16:04:38,288 INFO Training: [epoch:1, batch:  2200/7500] loss: 0.360
2021-05-03 16:04:48,301 INFO Training: [epoch:1, batch:  2250/7500] loss: 0.360
2021-05-03 16:04:58,259 INFO Training: [epoch:1, batch:  2300/7500] loss: 0.357
2021-05-03 16:05:10,110 INFO Training: [epoch:1, batch:  2350/7500] loss: 0.355
2021-05-03 16:05:22,586 INFO Training: [epoch:1, batch:  2400/7500] loss: 0.353
2021-05-03 16:05:37,178 INFO Training: [epoch:1, batch:  2450/7500] loss: 0.351
2021-05-03 16:05:49,632 INFO Training: [epoch:1, batch:  2500/7500] loss: 0.348
2021-05-03 16:06:02,354 INFO Training: [epoch:1, batch:  2550/7500] loss: 0.348
2021-05-03 16:06:14,147 INFO Training: [epoch:1, batch:  2600/7500] loss: 0.347
2021-05-03 16:06:24,651 INFO Training: [epoch:1, batch:  2650/7500] loss: 0.344
2021-05-03 16:06:36,185 INFO Training: [epoch:1, batch:  2700/7500] loss: 0.342
2021-05-03 16:06:47,909 INFO Training: [epoch:1, batch:  2750/7500] loss: 0.341
2021-05-03 16:06:58,597 INFO Training: [epoch:1, batch:  2800/7500] loss: 0.339
2021-05-03 16:07:10,996 INFO Training: [epoch:1, batch:  2850/7500] loss: 0.338
2021-05-03 16:07:22,823 INFO Training: [epoch:1, batch:  2900/7500] loss: 0.336
2021-05-03 16:07:35,044 INFO Training: [epoch:1, batch:  2950/7500] loss: 0.334
2021-05-03 16:07:45,607 INFO Training: [epoch:1, batch:  3000/7500] loss: 0.332
2021-05-03 16:07:55,679 INFO Training: [epoch:1, batch:  3050/7500] loss: 0.330
2021-05-03 16:08:08,050 INFO Training: [epoch:1, batch:  3100/7500] loss: 0.328
2021-05-03 16:08:21,059 INFO Training: [epoch:1, batch:  3150/7500] loss: 0.327
2021-05-03 16:09:23,806 INFO Training: [epoch:1, batch:  3200/7500] loss: 0.326
2021-05-03 16:09:43,780 INFO Training: [epoch:1, batch:  3250/7500] loss: 0.324
2021-05-03 16:10:06,443 INFO Training: [epoch:1, batch:  3300/7500] loss: 0.323
2021-05-03 16:10:20,469 INFO Training: [epoch:1, batch:  3350/7500] loss: 0.322
2021-05-03 16:10:32,877 INFO Training: [epoch:1, batch:  3400/7500] loss: 0.322
2021-05-03 16:10:43,285 INFO Training: [epoch:1, batch:  3450/7500] loss: 0.321
2021-05-03 16:10:53,621 INFO Training: [epoch:1, batch:  3500/7500] loss: 0.321
2021-05-03 16:11:03,267 INFO Training: [epoch:1, batch:  3550/7500] loss: 0.320
2021-05-03 16:11:15,551 INFO Training: [epoch:1, batch:  3600/7500] loss: 0.320
2021-05-03 16:11:28,334 INFO Training: [epoch:1, batch:  3650/7500] loss: 0.318
2021-05-03 16:11:45,128 INFO Training: [epoch:1, batch:  3700/7500] loss: 0.317
2021-05-03 16:11:56,254 INFO Training: [epoch:1, batch:  3750/7500] loss: 0.317
2021-05-03 16:12:05,646 INFO Training: [epoch:1, batch:  3800/7500] loss: 0.315
2021-05-03 16:12:16,577 INFO Training: [epoch:1, batch:  3850/7500] loss: 0.315
2021-05-03 16:12:28,328 INFO Training: [epoch:1, batch:  3900/7500] loss: 0.313
2021-05-03 16:12:41,793 INFO Training: [epoch:1, batch:  3950/7500] loss: 0.312
2021-05-03 16:12:52,894 INFO Training: [epoch:1, batch:  4000/7500] loss: 0.311
2021-05-03 16:13:03,767 INFO Training: [epoch:1, batch:  4050/7500] loss: 0.310
2021-05-03 16:13:15,720 INFO Training: [epoch:1, batch:  4100/7500] loss: 0.309
2021-05-03 16:13:28,135 INFO Training: [epoch:1, batch:  4150/7500] loss: 0.309
2021-05-03 16:13:39,428 INFO Training: [epoch:1, batch:  4200/7500] loss: 0.308
2021-05-03 16:13:49,591 INFO Training: [epoch:1, batch:  4250/7500] loss: 0.307
2021-05-03 16:14:00,118 INFO Training: [epoch:1, batch:  4300/7500] loss: 0.306
2021-05-03 16:14:13,280 INFO Training: [epoch:1, batch:  4350/7500] loss: 0.306
2021-05-03 16:14:24,392 INFO Training: [epoch:1, batch:  4400/7500] loss: 0.306
2021-05-03 16:14:35,889 INFO Training: [epoch:1, batch:  4450/7500] loss: 0.305
2021-05-03 16:14:47,526 INFO Training: [epoch:1, batch:  4500/7500] loss: 0.304
2021-05-03 16:14:59,045 INFO Training: [epoch:1, batch:  4550/7500] loss: 0.304
2021-05-03 16:15:50,303 INFO Training: [epoch:1, batch:  4600/7500] loss: 0.303
2021-05-03 16:16:18,942 INFO Training: [epoch:1, batch:  4650/7500] loss: 0.302
2021-05-03 16:16:43,365 INFO Training: [epoch:1, batch:  4700/7500] loss: 0.301
2021-05-03 16:16:54,804 INFO Training: [epoch:1, batch:  4750/7500] loss: 0.301
2021-05-03 16:17:04,931 INFO Training: [epoch:1, batch:  4800/7500] loss: 0.300
2021-05-03 16:17:14,565 INFO Training: [epoch:1, batch:  4850/7500] loss: 0.300
2021-05-03 16:17:27,171 INFO Training: [epoch:1, batch:  4900/7500] loss: 0.299
2021-05-03 16:17:39,658 INFO Training: [epoch:1, batch:  4950/7500] loss: 0.299
2021-05-03 16:17:54,722 INFO Training: [epoch:1, batch:  5000/7500] loss: 0.298
2021-05-03 16:18:05,609 INFO Training: [epoch:1, batch:  5050/7500] loss: 0.298
2021-05-03 16:18:16,516 INFO Training: [epoch:1, batch:  5100/7500] loss: 0.298
2021-05-03 16:18:29,448 INFO Training: [epoch:1, batch:  5150/7500] loss: 0.297
2021-05-03 16:18:41,640 INFO Training: [epoch:1, batch:  5200/7500] loss: 0.297
2021-05-03 16:18:54,013 INFO Training: [epoch:1, batch:  5250/7500] loss: 0.297
2021-05-03 16:19:03,995 INFO Training: [epoch:1, batch:  5300/7500] loss: 0.296
2021-05-03 16:19:14,112 INFO Training: [epoch:1, batch:  5350/7500] loss: 0.296
2021-05-03 16:19:26,796 INFO Training: [epoch:1, batch:  5400/7500] loss: 0.294
2021-05-03 16:19:37,822 INFO Training: [epoch:1, batch:  5450/7500] loss: 0.294
2021-05-03 16:19:49,993 INFO Training: [epoch:1, batch:  5500/7500] loss: 0.293
2021-05-03 16:19:59,732 INFO Training: [epoch:1, batch:  5550/7500] loss: 0.292
2021-05-03 16:20:12,637 INFO Training: [epoch:1, batch:  5600/7500] loss: 0.292
2021-05-03 16:20:23,043 INFO Training: [epoch:1, batch:  5650/7500] loss: 0.291
2021-05-03 16:20:33,326 INFO Training: [epoch:1, batch:  5700/7500] loss: 0.291
2021-05-03 16:21:18,649 INFO Training: [epoch:1, batch:  5750/7500] loss: 0.290
2021-05-03 16:21:55,798 INFO Training: [epoch:1, batch:  5800/7500] loss: 0.290
2021-05-03 16:22:12,460 INFO Training: [epoch:1, batch:  5850/7500] loss: 0.289
2021-05-03 16:22:28,538 INFO Training: [epoch:1, batch:  5900/7500] loss: 0.289
2021-05-03 16:22:42,246 INFO Training: [epoch:1, batch:  5950/7500] loss: 0.288
2021-05-03 16:22:54,805 INFO Training: [epoch:1, batch:  6000/7500] loss: 0.288
2021-05-03 16:23:07,852 INFO Training: [epoch:1, batch:  6050/7500] loss: 0.288
2021-05-03 16:23:24,638 INFO Training: [epoch:1, batch:  6100/7500] loss: 0.287
2021-05-03 16:23:40,643 INFO Training: [epoch:1, batch:  6150/7500] loss: 0.287
2021-05-03 16:23:56,717 INFO Training: [epoch:1, batch:  6200/7500] loss: 0.287
2021-05-03 16:24:10,530 INFO Training: [epoch:1, batch:  6250/7500] loss: 0.287
2021-05-03 16:24:20,853 INFO Training: [epoch:1, batch:  6300/7500] loss: 0.287
2021-05-03 16:24:32,896 INFO Training: [epoch:1, batch:  6350/7500] loss: 0.286
2021-05-03 16:24:45,938 INFO Training: [epoch:1, batch:  6400/7500] loss: 0.286
2021-05-03 16:24:58,817 INFO Training: [epoch:1, batch:  6450/7500] loss: 0.285
2021-05-03 16:25:12,208 INFO Training: [epoch:1, batch:  6500/7500] loss: 0.285
2021-05-03 16:25:24,384 INFO Training: [epoch:1, batch:  6550/7500] loss: 0.285
2021-05-03 16:25:37,414 INFO Training: [epoch:1, batch:  6600/7500] loss: 0.284
2021-05-03 16:25:51,897 INFO Training: [epoch:1, batch:  6650/7500] loss: 0.284
2021-05-03 16:26:05,605 INFO Training: [epoch:1, batch:  6700/7500] loss: 0.284
2021-05-03 16:26:17,054 INFO Training: [epoch:1, batch:  6750/7500] loss: 0.284
2021-05-03 16:26:26,758 INFO Training: [epoch:1, batch:  6800/7500] loss: 0.283
2021-05-03 16:26:38,747 INFO Training: [epoch:1, batch:  6850/7500] loss: 0.283
2021-05-03 16:26:50,247 INFO Training: [epoch:1, batch:  6900/7500] loss: 0.282
2021-05-03 16:27:51,575 INFO Training: [epoch:1, batch:  6950/7500] loss: 0.282
2021-05-03 16:28:15,958 INFO Training: [epoch:1, batch:  7000/7500] loss: 0.281
2021-05-03 16:28:38,385 INFO Training: [epoch:1, batch:  7050/7500] loss: 0.281
2021-05-03 16:28:52,924 INFO Training: [epoch:1, batch:  7100/7500] loss: 0.280
2021-05-03 16:29:04,592 INFO Training: [epoch:1, batch:  7150/7500] loss: 0.280
2021-05-03 16:29:15,137 INFO Training: [epoch:1, batch:  7200/7500] loss: 0.280
2021-05-03 16:29:25,720 INFO Training: [epoch:1, batch:  7250/7500] loss: 0.280
2021-05-03 16:29:38,662 INFO Training: [epoch:1, batch:  7300/7500] loss: 0.280
2021-05-03 16:29:53,084 INFO Training: [epoch:1, batch:  7350/7500] loss: 0.279
2021-05-03 16:30:10,577 INFO Training: [epoch:1, batch:  7400/7500] loss: 0.279
2021-05-03 16:30:23,723 INFO Training: [epoch:1, batch:  7450/7500] loss: 0.279
2021-05-03 16:30:34,986 INFO Training: [epoch:1, batch:  7500/7500] loss: 0.278
2021-05-03 16:30:39,982 INFO Validation: [epoch:1, batch:    50/1000] loss: 0.299 , accuracy: 91.500
2021-05-03 16:30:40,706 INFO Validation: [epoch:1, batch:   100/1000] loss: 0.336 , accuracy: 89.000
2021-05-03 16:30:41,355 INFO Validation: [epoch:1, batch:   150/1000] loss: 0.298 , accuracy: 90.500
2021-05-03 16:30:42,166 INFO Validation: [epoch:1, batch:   200/1000] loss: 0.288 , accuracy: 90.750
2021-05-03 16:30:42,792 INFO Validation: [epoch:1, batch:   250/1000] loss: 0.288 , accuracy: 90.300
2021-05-03 16:30:43,304 INFO Validation: [epoch:1, batch:   300/1000] loss: 0.272 , accuracy: 90.583
2021-05-03 16:30:43,795 INFO Validation: [epoch:1, batch:   350/1000] loss: 0.253 , accuracy: 91.214
2021-05-03 16:30:44,271 INFO Validation: [epoch:1, batch:   400/1000] loss: 0.250 , accuracy: 91.187
2021-05-03 16:30:44,728 INFO Validation: [epoch:1, batch:   450/1000] loss: 0.251 , accuracy: 91.333
2021-05-03 16:30:45,176 INFO Validation: [epoch:1, batch:   500/1000] loss: 0.256 , accuracy: 90.800
2021-05-03 16:30:45,702 INFO Validation: [epoch:1, batch:   550/1000] loss: 0.260 , accuracy: 90.409
2021-05-03 16:30:46,899 INFO Validation: [epoch:1, batch:   600/1000] loss: 0.252 , accuracy: 90.792
2021-05-03 16:30:48,500 INFO Validation: [epoch:1, batch:   650/1000] loss: 0.249 , accuracy: 90.769
2021-05-03 16:30:49,919 INFO Validation: [epoch:1, batch:   700/1000] loss: 0.258 , accuracy: 90.286
2021-05-03 16:30:50,619 INFO Validation: [epoch:1, batch:   750/1000] loss: 0.258 , accuracy: 90.100
2021-05-03 16:30:51,335 INFO Validation: [epoch:1, batch:   800/1000] loss: 0.262 , accuracy: 90.156
2021-05-03 16:30:52,050 INFO Validation: [epoch:1, batch:   850/1000] loss: 0.260 , accuracy: 90.206
2021-05-03 16:30:52,607 INFO Validation: [epoch:1, batch:   900/1000] loss: 0.258 , accuracy: 90.278
2021-05-03 16:30:53,088 INFO Validation: [epoch:1, batch:   950/1000] loss: 0.257 , accuracy: 90.526
2021-05-03 16:30:53,631 INFO Validation: [epoch:1, batch:  1000/1000] loss: 0.267 , accuracy: 90.400
2021-05-03 16:30:54,175 INFO save model with on epoch0 and validation loss 0.26706711348891277
2021-05-03 16:30:54,175 INFO Epoch 1
2021-05-03 16:31:09,892 INFO Training: [epoch:2, batch:    50/7500] loss: 0.169
2021-05-03 16:31:24,072 INFO Training: [epoch:2, batch:   100/7500] loss: 0.187
2021-05-03 16:31:34,489 INFO Training: [epoch:2, batch:   150/7500] loss: 0.188
2021-05-03 16:32:00,430 INFO Training: [epoch:2, batch:   200/7500] loss: 0.196
2021-05-03 16:32:58,764 INFO Training: [epoch:2, batch:   250/7500] loss: 0.193
2021-05-03 16:33:17,605 INFO Training: [epoch:2, batch:   300/7500] loss: 0.187
2021-05-03 16:33:36,669 INFO Training: [epoch:2, batch:   350/7500] loss: 0.192
2021-05-03 16:33:49,382 INFO Training: [epoch:2, batch:   400/7500] loss: 0.189
2021-05-03 16:33:59,824 INFO Training: [epoch:2, batch:   450/7500] loss: 0.187
2021-05-03 16:34:12,788 INFO Training: [epoch:2, batch:   500/7500] loss: 0.185
2021-05-03 16:34:25,476 INFO Training: [epoch:2, batch:   550/7500] loss: 0.188
2021-05-03 16:34:39,554 INFO Training: [epoch:2, batch:   600/7500] loss: 0.193
2021-05-03 16:34:54,226 INFO Training: [epoch:2, batch:   650/7500] loss: 0.195
2021-05-03 16:35:10,587 INFO Training: [epoch:2, batch:   700/7500] loss: 0.195
2021-05-03 16:35:22,443 INFO Training: [epoch:2, batch:   750/7500] loss: 0.194
2021-05-03 16:35:32,704 INFO Training: [epoch:2, batch:   800/7500] loss: 0.194
2021-05-03 16:35:43,692 INFO Training: [epoch:2, batch:   850/7500] loss: 0.192
2021-05-03 16:35:55,392 INFO Training: [epoch:2, batch:   900/7500] loss: 0.192
2021-05-03 16:36:06,581 INFO Training: [epoch:2, batch:   950/7500] loss: 0.190
2021-05-03 16:36:18,649 INFO Training: [epoch:2, batch:  1000/7500] loss: 0.191
2021-05-03 16:36:29,493 INFO Training: [epoch:2, batch:  1050/7500] loss: 0.191
2021-05-03 16:36:39,658 INFO Training: [epoch:2, batch:  1100/7500] loss: 0.192
2021-05-03 16:36:51,844 INFO Training: [epoch:2, batch:  1150/7500] loss: 0.192
2021-05-03 16:37:04,104 INFO Training: [epoch:2, batch:  1200/7500] loss: 0.193
2021-05-03 16:37:15,658 INFO Training: [epoch:2, batch:  1250/7500] loss: 0.192
2021-05-03 16:37:26,183 INFO Training: [epoch:2, batch:  1300/7500] loss: 0.192
2021-05-03 16:37:37,203 INFO Training: [epoch:2, batch:  1350/7500] loss: 0.192
2021-05-03 16:37:47,241 INFO Training: [epoch:2, batch:  1400/7500] loss: 0.192
